This Python script is a **simple spam message classifier** using **machine learning**. It uses the **Naive Bayes algorithm** and **CountVectorizer** from `scikit-learn` to identify whether a given message is spam or not.

---

### üß† **What It Does (In Simple Terms)**

* Takes a few example messages (some spam, some not).
* Learns from these messages using a machine learning model.
* Takes **user input** (a new message).
* Predicts whether that message is **Spam** or **Not Spam**.

---

### üß© **Step-by-Step Breakdown**

#### 1. **Imports**

```python
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.naive_bayes import MultinomialNB
```

* `CountVectorizer`: Converts text into numerical feature vectors (bag-of-words model).
* `MultinomialNB`: A Naive Bayes classifier suited for **text classification**, especially when features are word counts.

---

#### 2. **Sample Messages and Labels**

```python
messages = [
    "Win money now!",
    "Hello, how are you?",
    "Claim your free prize!!!",
    "Let's meet for lunch tomorrow",
    "Congratulations! You've won!"
]

labels = [1, 0, 1, 0, 1]
```

* These are **training examples**.
* Each message is either **spam (1)** or **not spam (0)**.
* This small dataset is just for demonstration.

---

#### 3. **Vectorizing the Messages**

```python
vectorizer = CountVectorizer()
features = vectorizer.fit_transform(messages)
```

* **`CountVectorizer`** converts each message into a **sparse matrix of word counts**.
* Example:

  ```
  "Win money now!" ‚Üí {'win': 1, 'money': 1, 'now': 1}
  ```

---

#### 4. **Training the Model**

```python
model = MultinomialNB()
model.fit(features, labels)
```

* Creates a **Naive Bayes model** using the `features` (vectorized messages) and `labels` (spam or not).
* The model learns which words are **more common in spam** versus not spam.

---

#### 5. **User Input and Prediction**

```python
test_msg = input("Enter a message to check if it's spam: ")
test_vector = vectorizer.transform([test_msg])
prediction = model.predict(test_vector)
```

* Takes a message from the user.
* Transforms it using the same vectorizer.
* Predicts whether it's **spam** or **not spam**.

---

#### 6. **Result Output**

```python
print("Spam" if prediction[0] == 1 else "Not Spam")
```

* Displays the result based on model output.

---

### üéØ Example Run

**Input:**

```
Enter a message to check if it's spam: You won a free prize!
```

**Output:**

```
Spam
```

---

### üî¨ How It Works Behind the Scenes

* **Naive Bayes** assumes word occurrences are independent.
* It calculates:

  ```
  P(Spam | Words) ‚àù P(Words | Spam) * P(Spam)
  ```
* Based on training, if words like "win", "prize", "free", etc. are seen often in spam, the model classifies messages with those words as spam.

---

### ‚ö†Ô∏è Limitations

* Very small training dataset ‚Äî accuracy is poor for real use.
* Doesn‚Äôt account for **word order** or **context**.
* Doesn‚Äôt clean or normalize text (e.g., remove punctuation, lowercase).
* Susceptible to misspellings or unseen words.

---

### ‚úÖ Improvements You Can Make

* Use a larger, labeled dataset like **SMS Spam Collection**.
* Preprocess text (lowercase, remove stop words, etc.).
* Try other models like **Logistic Regression**, **SVM**, or **deep learning**.
* Use `TfidfVectorizer` instead of `CountVectorizer`.

Would you like me to show how to add text preprocessing or load a real dataset?
